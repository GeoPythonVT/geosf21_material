{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Geo Data Science with Python\" \n",
    "### Notebook Exercise 7b\n",
    "\n",
    "---\n",
    "\n",
    "# Selecting points inside a boundary\n",
    "\n",
    "If you work in teams, please indicate your colaborators below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-Ctask",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "---\n",
    "# Part A: Find out which points locate inside a region (optional practice)\n",
    "\n",
    "(10 extra credit points)\n",
    "\n",
    "In the code cell below, you have given x and y coordiantes of two points p1 and p2 as well as an array containing a nested list of coordinate pairs. The data are defined in a code cell below this task. You are supposed to automatically test, whether the two points lcoate inside the polygon using Python code. For that you have to convert the points and the polygonArray to shapely objects and use the correct shapely function to assing the test result to two variables `test` and `test2`. In detail, perform the following steps:\n",
    "\n",
    "* Import the objects **Point** and **Polygon** from the package shapely.geometry in the way, that you do not need any prefix to use the objects Point and Polygon (1 point)\n",
    "* Define two points `p1` and `p2` as shapely Points, given the data below (2 points)\n",
    "* Convert the polygon given by the variable `polygonArray` to a list of tuples holding coordinate pairs and save them in the variable `PolygonList`. The structure of the list should be appropriate to serve as input for the shapely object Polygon in the next step. (3 points)\n",
    "* Define a shapely polygon `poly1` using the coordinates stored in `PolygonList` (1 point)\n",
    "* Check whether point `p1` and point `p2` locate in the polygon `poly1` and assign the test results to the variables `polytest1` and `polytest2`, respectively (2 points)\n",
    "\n",
    "Fill your code in the answer code cell below. Make sure to comment your code well!!! Use the same variable names as stated in the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-Ccode",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# x and y coordinates of two points, given as numbers\n",
    "p1_y = 24.952242\n",
    "p1_x = 60.1696017\n",
    "p2_y = 24.976567\n",
    "p2_x = 60.1612500\n",
    "\n",
    "# x and y coordinates of 4 points defining a polygon, given as a numpy array [y,x]\n",
    "polygonArray = np.array([[24.950899, 60.169158], [24.953492, 60.169158], [24.953510,60.170104], [24.950958,60.169990]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Add your code \"\"\"\n",
    "\n",
    "### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the results of your test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part B: Calculate statistics for a geographical region\n",
    "\n",
    "(25 points)\n",
    "\n",
    "In this task, you should retrieve a gridded dataset and calculate mean of one of three variables (surface temperature, snowfall **or** evaporation) within the state of California and Utah, during the month of January 2021.\n",
    "\n",
    "\n",
    "### You have given:\n",
    "\n",
    "- Link to the file containing one month GLDAS NOAH model simulations from NASA's GESDISC OpenDAP server defined as url below. Note: the dataset contains only one grid, we will not do any time series analysis, only work with the spatial (lat/lon) dimensions.\n",
    "- A file containing the boundary of California and Utah: boundary_CA.csv, boundary_UT.csv\n",
    "- Bounding box of the study region (encompassing both regions and a buffer):\n",
    "    - minLat = 28\n",
    "    - maxLat = 45\n",
    "    - minLon = -124\n",
    "    - maxLon = -106\n",
    "\n",
    "\n",
    "### You should do the following:\n",
    "\n",
    "- Import all needed packages\n",
    "- Read the boundary files for California and Utah\n",
    "- Open connection to the netcdf file via pydap and with your EarthData account\n",
    "- Retrieve information about either of the following variables from the GLDAS dataset: `AvgSurfT_inst`, `Snowf_tavg` or `Evap_tavg`.\n",
    "- Retrieve metdadata and mappings (lat, lon, ...)\n",
    "- Download the needed subset of the global dataset, covering the regions of California and Utah. **Note**: you will have to find indices that correspond to coordinates of the bounding box given above.\n",
    "- Find gridpoints located inside both states using classes and methods of the module shapely, and generate a mask for each of the regions of California and Utah\n",
    "- The mask should have the same shape as the downloaded datagrid its values should code 1 for gridpoints inside and 0 for gridpoints outside the region.\n",
    "- Apply the mask to the grid and calculate mean variable (surface temperature, snowfall or evaporation) for both regions. Note: consider a method, that does not include points outside the mask in the mean calculation, e.g. set points outside to nan and use np.nanmean().)\n",
    "- Make a testplot of your masks, to see if they are correct.\n",
    "- Generate a separate map of the grided dataset within the bounding box. Plot also the boundaries/polygons of both states.\n",
    "- Don't forget to comment your code\n",
    "- Structure your notebook into different work steps. Make use of the notebook markdown cells, add sections headers for different steps you are taking, or similar\n",
    "- Formulate a in a decent report answering the questions below, in a mark-down cell below your code cells.\n",
    "\n",
    "\n",
    "### Answer the following questions:\n",
    "\n",
    "- Which dataset did you choose (surface temperature, snowfall **or** evaporation) ?\n",
    "- What is the fill or missing value of the dataset ?\n",
    "- What is the unit of the dataset?\n",
    "- How many grid points locate inside the state of California?\n",
    "- How many grid points locate inside the state of Utah?\n",
    "- What is the average surface temperature / snowfall / evaporation during January 2021 in California?\n",
    "- What is the average surface temperature / snowfall / evaporation during January 2021 in Utah?\n",
    "- Which state got more snow during that month?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD YOUR CODE & Documentation in cells bellow\n",
    "### Create your own notebook structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add headers for steps in your program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Add your code for step 1 \"\"\"\n",
    "\n",
    "### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add headers for next step in your program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Add your code for step 2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Add your code for step 2\"\"\"\n",
    "\n",
    "### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
